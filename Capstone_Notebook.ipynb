{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a206b66",
   "metadata": {},
   "source": [
    "# Fake News Detction Model\n",
    "* Author: Ji Hoon Chung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d26f27",
   "metadata": {},
   "source": [
    "![Fakenews](Images/Fakenews.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de9f74",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0267a2",
   "metadata": {},
   "source": [
    "We are living in an unprecedented era where we are easily being exposed to tons of news on social media which we did not intend to spot. From premature juveniles to mature adults with higher degrees of education, fake news could easily deprive their factual senses and having them fallen down to imperfect beliefs. <br>\n",
    "\n",
    "Accordingly, it is crucial for social media platforms to detect fake news automatically to prohibit their exposure in the first place.<br>\n",
    "\n",
    "Our clients are Social Media Platforms like Facebook, Twitter, and LinkedIn. I would like to introduce a machine learning model being able to classify fake news aside from actual news using the words and patterns that are prevalent in conventional news dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87107789",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cec533",
   "metadata": {},
   "source": [
    "Dataset is obtained from source: https://drive.google.com/file/d/1er9NJTLUA3qnRuyhfzuN0XUsoIC4a-_q/view <br>\n",
    "\n",
    "I’ve collected a dataset which includes 6,335 rows of data containing 3,171 real news vs 3,164 fake news. Dataset is very straight forward containing only 3 columns such as, title, text (article contents), and label indicating real or fake.<br>\n",
    "\n",
    "Machine Learning Model will be built after tweaking the dataset as below:\n",
    "1. Text Data will be combined with Title.\n",
    "2. 2nd column will be created with lemmmatized text.\n",
    "3. 3rd column will be created with stemmed text.\n",
    "4. Dataset will be resampled with 0.17:1.0 FAKE to REAL news ratio. (Real World Fake to Real news ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69085a3a",
   "metadata": {},
   "source": [
    "# 1. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2522109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import string\n",
    "import warnings\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report, plot_roc_curve, auc, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import inaugural, wordnet, stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WhitespaceTokenizer as w_tokenizer\n",
    "from nltk.tag import pos_tag\n",
    "from collections import Counter\n",
    "from itertools import chain, filterfalse as ifilterfalse\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "from statsmodels.formula.api import ols\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc2a594",
   "metadata": {},
   "source": [
    "## 1.1 Load & Clean Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23591a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv(\"./data/news 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e621fa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>2550</td>\n",
       "      <td>Trump: Undocumented Children Aren't US Citizens</td>\n",
       "      <td>Billionare Donald Trump is doubling down on hi...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>6738</td>\n",
       "      <td>Even Doctors Are Surprised: This Recipe Renews...</td>\n",
       "      <td>Share on Facebook Experts claim that the impro...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>7767</td>\n",
       "      <td>DISGUSTING Evolution Of Political Correctness ...</td>\n",
       "      <td>You are here: Home / US / DISGUSTING Evolution...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>7235</td>\n",
       "      <td>French Jews urged to rally over UNESCO resolut...</td>\n",
       "      <td>October 28, 2016 French Jews urged to rally ov...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>8818</td>\n",
       "      <td>GOVERNMENT HIDING UNPRECEDENTED TB INFECTION R...</td>\n",
       "      <td>Home › HEALTH › GOVERNMENT HIDING UNPRECEDENTE...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>9153</td>\n",
       "      <td>Why Everyone on Facebook Is Checking into Stan...</td>\n",
       "      <td>Pin 1 \\n( ANTIMEDIA ) When it comes to brute f...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>10457</td>\n",
       "      <td>Reasons to Risk Nuclear Annihilation</td>\n",
       "      <td>Reasons to Risk Nuclear Annihilation   latest ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>9015</td>\n",
       "      <td>Clinton, FBIGate and the true depth of the Oba...</td>\n",
       "      <td>Clinton, FBIGate and the true depth of the Oba...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>4128</td>\n",
       "      <td>Surviving escaped prisoner likely fatigued and...</td>\n",
       "      <td>Police searching for the second of two escaped...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>9196</td>\n",
       "      <td>Re: WikiLeaks: Neera Tanden has ANOTHER ringin...</td>\n",
       "      <td>WikiLeaks: Neera Tanden has ANOTHER ringing en...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "3860        2550    Trump: Undocumented Children Aren't US Citizens   \n",
       "3467        6738  Even Doctors Are Surprised: This Recipe Renews...   \n",
       "5146        7767  DISGUSTING Evolution Of Political Correctness ...   \n",
       "5263        7235  French Jews urged to rally over UNESCO resolut...   \n",
       "3820        8818  GOVERNMENT HIDING UNPRECEDENTED TB INFECTION R...   \n",
       "1731        9153  Why Everyone on Facebook Is Checking into Stan...   \n",
       "1037       10457               Reasons to Risk Nuclear Annihilation   \n",
       "5191        9015  Clinton, FBIGate and the true depth of the Oba...   \n",
       "4002        4128  Surviving escaped prisoner likely fatigued and...   \n",
       "302         9196  Re: WikiLeaks: Neera Tanden has ANOTHER ringin...   \n",
       "\n",
       "                                                   text label  \n",
       "3860  Billionare Donald Trump is doubling down on hi...  REAL  \n",
       "3467  Share on Facebook Experts claim that the impro...  FAKE  \n",
       "5146  You are here: Home / US / DISGUSTING Evolution...  FAKE  \n",
       "5263  October 28, 2016 French Jews urged to rally ov...  FAKE  \n",
       "3820  Home › HEALTH › GOVERNMENT HIDING UNPRECEDENTE...  FAKE  \n",
       "1731  Pin 1 \\n( ANTIMEDIA ) When it comes to brute f...  FAKE  \n",
       "1037  Reasons to Risk Nuclear Annihilation   latest ...  FAKE  \n",
       "5191  Clinton, FBIGate and the true depth of the Oba...  FAKE  \n",
       "4002  Police searching for the second of two escaped...  REAL  \n",
       "302   WikiLeaks: Neera Tanden has ANOTHER ringing en...  FAKE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Overview\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5321ee",
   "metadata": {},
   "source": [
    "It seems like most of the news are political within political category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872ed74f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "title         0\n",
       "text          0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b289c0b",
   "metadata": {},
   "source": [
    "Null value does not exist within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74771d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine Title into text and drop title from the dataframe.\n",
    "df['text'] = df['title'] + df['text']\n",
    "df.drop('title', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542de4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s FearDaniel Greenfield,...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathyU.S...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text label\n",
       "0        8476  You Can Smell Hillary’s FearDaniel Greenfield,...  FAKE\n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...  FAKE\n",
       "2        3608  Kerry to go to Paris in gesture of sympathyU.S...  REAL\n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...  FAKE\n",
       "4         875  The Battle of New York: Why This Primary Matte...  REAL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text and Title are combined.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ded65b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns.\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde2523",
   "metadata": {},
   "source": [
    "## 1.2 Lemmatization & Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649fdc26",
   "metadata": {},
   "source": [
    "For more detailed investigation on the text, I will prepare lemmatized & stemmed text dataset to see if these will bring better accuracy on our classification model later on.<br>\n",
    "\n",
    "1. In lemmatization, the part of speech of a word should be first determined and the normalisation rules will be different for different part of speech, while the stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech. <br>\n",
    "<br>\n",
    "2. A stemmer will return the stem of a word, which needn't be identical to the morphological root of the word. It usually sufficient that related words map to the same stem,even if the stem is not in itself a valid root, while in lemmatisation, it will return the dictionary form of a word, which must be a valid word.\n",
    "<br><br>\n",
    "Source: https://stackoverflow.com/questions/1787110/what-is-the-difference-between-lemmatization-vs-stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1659b5",
   "metadata": {},
   "source": [
    "### 1.2.1 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b19c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatzie Fundtion after POS-TAG\n",
    "def lemmatize_all(sentence):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    for word, tag in pos_tag(word_tokenize(sentence)):\n",
    "        if tag.startswith(\"NN\"):\n",
    "            yield wnl.lemmatize(word, pos='n')\n",
    "        elif tag.startswith('VB'):\n",
    "            yield wnl.lemmatize(word, pos='v')\n",
    "        elif tag.startswith('JJ'):\n",
    "            yield wnl.lemmatize(word, pos='a')\n",
    "        else:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6b2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Lemmatized Text with a space.\n",
    "def join_lemmatize(lem):\n",
    "    return ' '.join(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "800ff83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tokens lemmatized.\n",
    "df['lemmatized_text'] = df['text'].apply((lemmatize_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f13a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct lemmatized dataset.\n",
    "df['lemmatized_text'] = df['lemmatized_text'].apply((join_lemmatize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ebddcb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s FearDaniel Greenfield,...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>You Can Smell Hillary ’ s FearDaniel Greenfiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathyU.S...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathyU.S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Bernie supporter on Twitter erupt in anger aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>The Battle of New York : Why This Primary Matt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0  You Can Smell Hillary’s FearDaniel Greenfield,...  FAKE   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...  FAKE   \n",
       "2  Kerry to go to Paris in gesture of sympathyU.S...  REAL   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...  FAKE   \n",
       "4  The Battle of New York: Why This Primary Matte...  REAL   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  You Can Smell Hillary ’ s FearDaniel Greenfiel...  \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...  \n",
       "2  Kerry to go to Paris in gesture of sympathyU.S...  \n",
       "3  Bernie supporter on Twitter erupt in anger aga...  \n",
       "4  The Battle of New York : Why This Primary Matt...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97386e0c",
   "metadata": {},
   "source": [
    "### 1.2.2 Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b71be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Tokenize Dataset\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "df['tokenized_sents'] = df.apply(lambda row: w_tokenizer.tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a137a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmer Function\n",
    "def stemmer_text(text):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(w) for w in text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279cf485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consturct Stemmed dataset.\n",
    "df['stemmer_text'] = df['tokenized_sents'].apply(stemmer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbf811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(text):\n",
    "    return ' '.join(str(e) for e in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee431468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert List to String\n",
    "df['stemmer_text'] = df['stemmer_text'].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Dataset for Model Building\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3426eb50",
   "metadata": {},
   "source": [
    "## 1.3 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4943641",
   "metadata": {},
   "source": [
    "### 1.3.1 Text length comparison between FAKE vs. REAL News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a10e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"words_used\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ea534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See how may words are used per text\n",
    "for i in range(len(df.text)-1):\n",
    "    df['words_used'].iloc[i] = len(df['text'].iloc[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f46e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_words = df.groupby('label').agg({'words_used':['mean', 'median', 'std', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = len(df['text'].iloc[1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d4367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_words.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2426735",
   "metadata": {},
   "source": [
    "FAKE news articles contains less mean & median number of words whereas their standard deviation is a lot larger indicating they have more versatility in lengh of an article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066d1d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,8))\n",
    "ax = sns.boxplot(x='label', y='words_used', data=df)\n",
    "ax.set_ylim(0,1500)\n",
    "ax.set_title('# of Words Trend in Fake & Real News')\n",
    "plt.savefig('./images/word_trend.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ebde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.words_used.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de43c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Conduct 2-Sample T-Test to see if we can reject null hypothesis.\n",
    "stats.ttest_ind(df[df.label=='FAKE']['words_used'], df[df.label=='REAL']['words_used'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e85750",
   "metadata": {},
   "source": [
    "Overally, FAKE news has lower average length compared to REAL news. <br>\n",
    "Since Two Sample T-Test shows significantly low p-value less than 0.05, we can reject the null hypothesis: <br>\n",
    "<b>Number of words used is significantly related with the news article being FAKE or REAL.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab60d96",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9f36f",
   "metadata": {},
   "source": [
    "### 1.3.2 Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e61b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fake News Word Cloud\n",
    "plt.figure(figsize = (20,20)) # Text from the real news articles\n",
    "wc = WordCloud(max_words = 3000 , width = 1600 , height = 800 , \n",
    "               stopwords = STOPWORDS).generate(\" \".join(df[df.label == 'FAKE'].text))\n",
    "plt.imshow(wc , interpolation = 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show\n",
    "plt.savefig('./images/Fake_wordcloud.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf1c10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Real News Word Cloud\n",
    "plt.figure(figsize = (20,20)) # Text from the real news articles\n",
    "wc = WordCloud(max_words = 3000 , width = 1600 , height = 800 , \n",
    "               stopwords = STOPWORDS).generate(\" \".join(df[df.label == 'REAL'].text))\n",
    "plt.imshow(wc , interpolation = 'bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show\n",
    "plt.savefig('./images/Real_wordcloud.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a07107",
   "metadata": {},
   "source": [
    "Looking at word Cloud, it's hard to tell the distinction between two types of articles. However, it is evident that both articles are mainly about the US politics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cdc8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67b232",
   "metadata": {},
   "source": [
    "### 1.3.3 Top 10 Word Frequency Distribution Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380de83",
   "metadata": {},
   "source": [
    "Since Wordcloud does not bring too much insightful information, let's try comparing Top 10 Word counts per Article Type using barplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Words Function with the stopwords excluded from the count\n",
    "def countwords(text):\n",
    "    stops = stopwords.words('english')\n",
    "    words = chain.from_iterable(line.split() for line in text)\n",
    "    return Counter(word for word in words if word not in stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ac6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Real News Word Count Dataset, change all text into lowercase to enable stopwords\n",
    "df_real = df[df.label=='REAL']\n",
    "df_real = df_real.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dbdc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FAKE News Word Count Dataset, change all text into lowercase to enable stopwords\n",
    "df_fake = df[df.label=='FAKE']\n",
    "df_fake = df_fake.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Real News Word Counts\n",
    "wordcount_real = countwords(df_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set FAKE News Word Counts\n",
    "wordcount_fake = countwords(df_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99328841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Top 10 most common words\n",
    "wordcount_real = wordcount_real.most_common(10)\n",
    "wordcount_fake = wordcount_fake.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve X and Y values of the words and word counts\n",
    "x_real = []\n",
    "y_real = []\n",
    "\n",
    "for i in range (10):\n",
    "    x_real.append(wordcount_real[i][0])\n",
    "    y_real.append(wordcount_real[i][1])\n",
    "    \n",
    "x_fake = []\n",
    "y_fake = []\n",
    "\n",
    "for i in range (10):\n",
    "    x_fake.append(wordcount_fake[i][0])\n",
    "    y_fake.append(wordcount_fake[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d4759",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the barplot of TOP 10 Word Counts for REAL & FAKE News.\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(20,14))\n",
    "\n",
    "ax1.bar(x_real, y_real, color= (0.1, 0.1, 0.1, 0.1),  edgecolor='blue')\n",
    "ax2.bar(x_fake, y_fake, color= (0.1, 0.1, 0.1, 0.1),  edgecolor='red')\n",
    "\n",
    "ax1.set_title('Top 10 Word Counts in REAL News', fontdict = {'fontsize':15, 'fontweight':'bold', 'color':'blue'})\n",
    "ax2.set_title('Top 10 Word Counts in FAKE News', fontdict = {'fontsize':15, 'fontweight':'bold', 'color':'red'})\n",
    "\n",
    "ax1.tick_params(axis='x', which='major', labelsize=15)\n",
    "ax2.tick_params(axis='x', which='major', labelsize=15)\n",
    "\n",
    "plt.savefig('./images/Top10_WordCounts.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5e9c8",
   "metadata": {},
   "source": [
    "According to the Plot, there are a few notable differences between REAL & FAKE NEWS:\n",
    "1. Trump was much widely used in REAL news whereas Clinton was more widely used in FAKE News.\n",
    "2. It looks like FAKE news was more susceptible in using Full Name of Hilary Clinton.\n",
    "3. 'US' was very widely used in FAKE news wheareas it was not one of the TOP 10 words in REAL news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494202b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010376e",
   "metadata": {},
   "source": [
    "# 2. General Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429a986",
   "metadata": {},
   "source": [
    "## 2.1 Splitting Dataset for Modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9350e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Text X\n",
    "X_text = df['text']\n",
    "\n",
    "# Stemmed Text X\n",
    "X_stem = df['stemmer_text']\n",
    "\n",
    "#Lemmatized Text X\n",
    "X_lem = df['lemmatized_text']\n",
    "\n",
    "#Target Variable\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(np.where(y=='FAKE', 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9787e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Split the dataset (For Original Text)\n",
    "x_text_train, x_text_test, y_text_train, y_text_test=train_test_split(X_text, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2006068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Split the dataset (For Stemmed Text)\n",
    "x_stem_train, x_stem_test, y_stem_train, y_stem_test=train_test_split(X_stem, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Split the dataset (For Lemmatized Text)\n",
    "x_lem_train, x_lem_test, y_lem_train, y_lem_test=train_test_split(X_lem, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fa650",
   "metadata": {},
   "source": [
    "## 2.2 Decision Tree Model (Without Adjusting Class Balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with TfIDFVectorizer and Decision Tree Classifer\n",
    "tree_tf_pipeline = Pipeline([('vect',TfidfVectorizer()),\n",
    "                 ('tree',DecisionTreeClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'tree__max_depth': [8, 14, 20]}]\n",
    "\n",
    "# Define a grid search\n",
    "gs1 = GridSearchCV(estimator=tree_tf_pipeline, \n",
    "                          param_grid=grid, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ddb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with CountVectorizer and Decision Tree Classifer\n",
    "tree_ct_pipeline = Pipeline([('vect',CountVectorizer()),\n",
    "                 ('tree',DecisionTreeClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'tree__max_depth': [8, 14, 20]}]\n",
    "\n",
    "# Define a grid search\n",
    "gs2 = GridSearchCV(estimator=tree_ct_pipeline, \n",
    "                          param_grid=grid, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3821ef8",
   "metadata": {},
   "source": [
    "### 2.2.1 TFIDF Vectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66218de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs1.fit(x_text_train, y_text_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4adc05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs1.fit(x_lem_train, y_text_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731578e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs1.fit(x_stem_train, y_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c4059",
   "metadata": {},
   "source": [
    "For TfIDF Vectorizer, Best F1_Score came with the Stemmed Text Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c1af9",
   "metadata": {},
   "source": [
    "### 2.2.2 CountVectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs2.fit(x_text_train, y_text_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs2.fit(x_stem_train, y_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6716d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs2.fit(x_lem_train, y_text_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c0385",
   "metadata": {},
   "source": [
    "For CountVectorizer, All the Datasets have to same F1_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081e223",
   "metadata": {},
   "source": [
    "### 2.2.3 Decision Tree Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f86841",
   "metadata": {},
   "source": [
    "<B>TFIDF Vectorizer with Stemmed Datasets showed best F1_Score in validation Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30867686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the model for tf-idf features\n",
    "tree_tf_stem_pred = gs1.predict(x_stem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b19fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy score for tfidf features\n",
    "Tree_tfidf_score=accuracy_score(y_stem_test, tree_tf_stem_pred)\n",
    "print(\"Decision Tree TF-IDF accuracy score:\", Tree_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92223a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x_teset_tfidf value for Confusion Matrix Evaluation\n",
    "gs1_x_test_tfidf = gs1.best_estimator_.named_steps['vect'].transform(x_stem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334609e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Tree_cm = plot_confusion_matrix(gs1.best_estimator_.named_steps['tree'], gs1_x_test_tfidf , y_stem_test)\n",
    "plt.suptitle(\"Raw Data Decision Tree Confusion Matrix\")\n",
    "plt.savefig('./images/Raw_Tree_cf.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14723b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tree_roc = plot_roc_curve(gs1.best_estimator_.named_steps['tree'] ,gs1_x_test_tfidf, y_stem_test)\n",
    "plt.suptitle(\"Raw Data Decision Tree ROC Curve\")\n",
    "plt.savefig('./images/Raw_Tree_ROC.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c77130",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Tree_tfidf_report = classification_report(y_test, Tree_tfidf_pred, target_names = ['FAKE','REAL'])\n",
    "print(Tree_tfidf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f6bca",
   "metadata": {},
   "source": [
    "Accuray of model with the raw dataset seems pretty satisfying. However, class imbalance clearly exists between REAL vs FAKE news in Real World. Since my mission is to bring a model that can be fully utilized in real world, I will bring in class imbalance of target variable in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81763ba6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599c17b",
   "metadata": {},
   "source": [
    "## 3. Modeling After Setting Up Class Imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b114ac",
   "metadata": {},
   "source": [
    "By the numbers: In 2020, nearly one-fifth <b>(17%)</b> of engagement among the top 100 news sources on social media came from sources that NewsGuard deems generally unreliable, compared to about 8% in 2019.<br>\n",
    "<br>\n",
    "Source = https://www.axios.com/unreliable-news-sources-social-media-engagement-297bf046-c1b0-4e69-9875-05443b1dca73.html?utm_campaign=organic&utm_medium=socialshare&utm_source=twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba96ce3",
   "metadata": {},
   "source": [
    "<B>Entire Dataset will be re-sampled into 0.17:1.0 FAKE to REAL news ratio so that it actually resembles FAKE news ratio being spread in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d24b0",
   "metadata": {},
   "source": [
    "## 3.1 Resampling Dataset (0.17 : 1.0) FAKE to REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f23d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import make_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74693bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Text X\n",
    "X_text = pd.DataFrame(X_text)\n",
    "\n",
    "# Stemmed Text X\n",
    "X_stem = pd.DataFrame(X_stem)\n",
    "\n",
    "#Lemmatized Text X\n",
    "X_lem = pd.DataFrame(X_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cebfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Original Text, Create imbalanced Dataset (0.17:1 Fake vs. Real News Ratio)\n",
    "x_im_text, y_im_text = make_imbalance(X_text,y,sampling_strategy={1: 539, 0: 3171})\n",
    "\n",
    "# Stemmed Text, Create imbalanced Dataset (0.17:1 Fake vs. Real News Ratio)\n",
    "x_im_stem, y_im_stem = make_imbalance(X_stem,y,sampling_strategy={1: 539, 0: 3171})\n",
    "\n",
    "# Lemmatized Text, Create imbalanced Dataset (0.17:1 Fake vs. Real News Ratio)\n",
    "x_im_lem, y_im_lem = make_imbalance(X_lem,y,sampling_strategy={1: 539, 0: 3171})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_im_text = x_im_text['text']\n",
    "x_im_stem = x_im_stem['stemmer_text']\n",
    "x_im_lem = x_im_lem['lemmatized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886050b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Split the dataset - Original text\n",
    "x_im_train, x_im_test, y_im_train, y_im_test = train_test_split(x_im_text, y_im_text, test_size=0.2, random_state=7)\n",
    "\n",
    "#DataFlair - Split the dataset - Stemmed text\n",
    "x_im_stem_train, x_im_stem_test, y_im_stem_train, y_im_stem_test = train_test_split(x_im_stem, y_im_stem, test_size=0.2, random_state=7)\n",
    "\n",
    "#DataFlair - Split the dataset - Lemmaitzed text\n",
    "x_im_lem_train, x_im_lem_test, y_im_lem_train, y_im_lem_test = train_test_split(x_im_lem, y_im_lem, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d23b3be",
   "metadata": {},
   "source": [
    "Dataset & Splitting is Ready!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10079c11",
   "metadata": {},
   "source": [
    "## 3.2 Dummy Model after resampling Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f9b449",
   "metadata": {},
   "source": [
    "Dummy Model needs to be constructed to evaluate performance going forward as Target Variable class is highly imbalanced.<br>\n",
    "Model for only one of the datasets would be necessary as it is Dummy Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b50954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with TFIDF and DummyClassifer\n",
    "dummy_pipeline = Pipeline([('vect',TfidfVectorizer()),\n",
    "                 ('dummy',DummyClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid_3 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'dummy__strategy': ['most_frequent']}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_3 = GridSearchCV(estimator=dummy_pipeline, \n",
    "                          param_grid=grid_3, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the training data\n",
    "gs_3.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the model for tf-idf features\n",
    "dummy_pred = gs_3.predict(x_im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d8f04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the accuracy score for tfidf features\n",
    "dummy_score=accuracy_score(y_im_test, dummy_pred)\n",
    "print(\"Decision Tree TF-IDF accuracy score:\", dummy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x_teset_tfidf value for Confusion Matrix Evaluation\n",
    "gs_3_x_test_tfidf = gs_3.best_estimator_.named_steps['vect'].transform(x_im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d87613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_cm = plot_confusion_matrix(gs_3.best_estimator_.named_steps['dummy'], gs_3_x_test_tfidf, y_im_test)\n",
    "plt.suptitle(\"Dummy Classifier Confusion Matrix\")\n",
    "plt.savefig('./images/Dummy_cf.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e606a78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_report = classification_report(y_im_test, dummy_pred, target_names = ['0', '1'])\n",
    "print(dummy_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf5170",
   "metadata": {},
   "source": [
    "<b>Since Dummy Score has Accuracy-Score of 0.857, our model should draw Accuracy Score at least better than 0.857."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a00d80",
   "metadata": {},
   "source": [
    "## 3.3 Decision Tree Model after Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with TFIDF, SMOTE and Decision Tree Classifer, SMOTE was added to rebalance Training Data.\n",
    "tree_pipeline_2 = Pipeline([('vect',TfidfVectorizer()),\n",
    "                            ('smote', SMOTE()),\n",
    "                 ('tree',DecisionTreeClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid_4 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'tree__max_depth': [8, 14, 20]}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_4 = GridSearchCV(estimator=tree_pipeline_2, \n",
    "                          param_grid=grid_4, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6505e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with TFIDF, SMOTE and CountVectorizer, SMOTE was added to rebalance Training Data.\n",
    "tree_pipeline_3 = Pipeline([('vect',CountVectorizer()),\n",
    "                            ('smote', SMOTE()),\n",
    "                 ('tree',DecisionTreeClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid_5 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'tree__max_depth': [8, 14, 20]}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_5 = GridSearchCV(estimator=tree_pipeline_3, \n",
    "                          param_grid=grid_5, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaad49c",
   "metadata": {},
   "source": [
    "### 3.3.1 TFIDF Vectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81ccfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs_4.fit(x_im_lem_train, y_im_lem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10389f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs_4.fit(x_im_stem_train, y_im_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs_4.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec803b8",
   "metadata": {},
   "source": [
    "### 3.3.2 CountVectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afba78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs_5.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2921a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs_5.fit(x_im_lem_train, y_im_lem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6304d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs_5.fit(x_im_stem_train, y_im_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_5.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb1602",
   "metadata": {},
   "source": [
    "### 3.3.3 Decision Tree Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the model for tf-idf features\n",
    "tree_tf_imb_pred = gs_4.predict(x_im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef228b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy score for tfidf features\n",
    "Tree_tfimb_score=accuracy_score(y_im_test, tree_tf_imb_pred)\n",
    "print(\"Decision Tree TF-IDF accuracy score:\", Tree_tfimb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x_teset_tfidf value for Confusion Matrix Evaluation\n",
    "gs4_x_test_tfimb = gs_4.best_estimator_.named_steps['vect'].transform(x_im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540aeac1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Tree_imb_cm = plot_confusion_matrix(gs_4.best_estimator_.named_steps['tree'], gs4_x_test_tfimb , y_im_test)\n",
    "plt.suptitle(\"Imbalance Data DecisionTree Confusion Matrix\")\n",
    "plt.savefig('./images/Imb_Tree_cf.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac650e3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Tree_imb_roc = plot_roc_curve(gs_4.best_estimator_.named_steps['tree'] ,gs4_x_test_tfimb, y_im_test)\n",
    "plt.suptitle(\"Imbalance Data DecisionTree ROC Curve\")\n",
    "plt.savefig('./images/Imb_Tree_ROC.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2447d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tree_tfimb_report = classification_report(y_im_test, tree_tf_imb_pred, target_names = ['0','1'])\n",
    "print(Tree_tfimb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61d1af",
   "metadata": {},
   "source": [
    "Accuracy Score is better than DummyClassifier at 0.869 which is <b>0.012</b> higher than DummyClassifer.<br>\n",
    "However, we could do better than this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ccb22",
   "metadata": {},
   "source": [
    "## 3.4 RandomForest Model after Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51229d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with TFIDF and RandomForestClassifier\n",
    "rdf_pipeline = Pipeline([('vect',TfidfVectorizer()),\n",
    "                         ('smote', SMOTE()),\n",
    "                 ('rdf',RandomForestClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid_6 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'rdf__n_estimators': [10, 20, 30, 40]}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_6 = GridSearchCV(estimator=rdf_pipeline, \n",
    "                          param_grid=grid_6, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6037d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with CountVectorizer and RandomForestClassifier\n",
    "rdf_pipeline2 = Pipeline([('vect',CountVectorizer()),\n",
    "                          ('smote', SMOTE()),\n",
    "                 ('rdf',RandomForestClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid_7 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'rdf__n_estimators': [10, 20, 30, 40]}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_7 = GridSearchCV(estimator=rdf_pipeline2, \n",
    "                          param_grid=grid_7, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d186fe4a",
   "metadata": {},
   "source": [
    "### 3.4.1 TFIDF Vectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc11256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs_6.fit(x_im_lem_train, y_im_lem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee28c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs_6.fit(x_im_stem_train, y_im_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3aece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs_6.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_6.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651eda5",
   "metadata": {},
   "source": [
    "### 3.4.2 CountVectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e515dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs_7.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_7.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f8ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs_7.fit(x_im_lem_train, y_im_lem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_7.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dae79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs_7.fit(x_im_stem_train, y_im_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_7.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5c65c",
   "metadata": {},
   "source": [
    "### 3.4.3 RandomForest Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the model for tf-idf features\n",
    "dec_imb_pred = gs_6.predict(x_im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a197801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy score for tfidf features\n",
    "dec_imb_score=accuracy_score(y_im_test, dec_imb_pred)\n",
    "print(\"RandomForest TF-IDF accuracy score:\", dec_imb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c108a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x_teset_tfidf value for Confusion Matrix Evaluation\n",
    "gs6_rf_tfidf = gs_6.best_estimator_.named_steps['vect'].transform(x_im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfb_cm = plot_confusion_matrix(gs_6.best_estimator_.named_steps['rdf'], gs6_rf_tfidf , y_im_test)\n",
    "plt.suptitle(\"Imbalance Data RandomForest Confusion Matrix\")\n",
    "plt.savefig('./images/Imb_RF_cf.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f8a61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfb_roc = plot_roc_curve(gs_6.best_estimator_.named_steps['rdf'] ,gs6_rf_tfidf, y_im_test)\n",
    "plt.suptitle(\"Imbalance Data RandomForest ROC Curve\")\n",
    "plt.savefig('./images/Imb_RF_ROC.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2aa17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfb_report = classification_report(y_im_test, dec_imb_pred, target_names = ['0','1'])\n",
    "print(rfb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a2eb7",
   "metadata": {},
   "source": [
    "Accuracy Score is high. However in terms of Fake News F1-Score it is lower than DecisionTree model. We would need a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8771e5",
   "metadata": {},
   "source": [
    "## 3.5 Multinomial Model after Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecf108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with TFIDF and MultinomialClassifier\n",
    "mlb_pipeline = Pipeline([('vect',TfidfVectorizer()),\n",
    "                         ('smote', SMOTE()),\n",
    "                 ('mlb',MultinomialNB())])\n",
    "\n",
    "# Define the grid\n",
    "grid_8 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_8 = GridSearchCV(estimator=mlb_pipeline, \n",
    "                          param_grid=grid_8, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with CountVectorizer and MultinomialClassifier\n",
    "mlb_pipeline2 = Pipeline([('vect',CountVectorizer()),\n",
    "                         ('smote', SMOTE()),\n",
    "                 ('mlb',MultinomialNB())])\n",
    "\n",
    "# Define the grid\n",
    "grid_9 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_9 = GridSearchCV(estimator=mlb_pipeline2, \n",
    "                          param_grid=grid_9, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aa39e",
   "metadata": {},
   "source": [
    "### 3.5.1 TFIDF Vectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81ccfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs_8.fit(x_im_lem_train, y_im_lem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_8.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs_8.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_8.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10389f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs_8.fit(x_im_stem_train, y_im_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_8.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec803b8",
   "metadata": {},
   "source": [
    "### 3.5.2 CountVectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afba78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs_9.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_9.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2921a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs_9.fit(x_im_lem_train, y_im_lem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_9.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6304d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs_9.fit(x_im_stem_train, y_im_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_9.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb1602",
   "metadata": {},
   "source": [
    "### 3.5.3 MultiNomial Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf54339",
   "metadata": {},
   "source": [
    "Stemmed TFIDF Vectorizor is the best model according to CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the model for tf-idf features\n",
    "mlb_imb_pred = gs_8.predict(x_im_stem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef228b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the accuracy score for tfidf features\n",
    "mlb_imb_score=accuracy_score(y_im_stem_test, mlb_imb_pred)\n",
    "print(\"RandomForest TF-IDF accuracy score:\", mlb_imb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x_teset_tfidf value for Confusion Matrix Evaluation\n",
    "gs8_mlb_tfidf = gs_8.best_estimator_.named_steps['vect'].transform(x_im_stem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_cm = plot_confusion_matrix(gs_8.best_estimator_.named_steps['mlb'], gs8_mlb_tfidf , y_im_stem_test)\n",
    "plt.suptitle(\"Imbalance Data MultiNomial Confusion Matrix\")\n",
    "plt.savefig('./images/Imb_MNB_CF.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14723b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlb_roc = plot_roc_curve(gs_8.best_estimator_.named_steps['mlb'] ,gs8_mlb_tfidf, y_im_stem_test)\n",
    "plt.suptitle(\"Imbalance Data MultiNomial ROC Curve\")\n",
    "plt.savefig('./images/Imb_MNB_ROC.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c77130",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlb_report = classification_report(y_im_stem_test, mlb_imb_pred, target_names = ['0','1'])\n",
    "print(mlb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e303242e",
   "metadata": {},
   "source": [
    "Multinomial model is definitely much more terrific than all the previous models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8771e5",
   "metadata": {},
   "source": [
    "## 3.6 PassiveAggressiveClassifier Model after Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51229d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with TFIDF and MultinomialClassifier\n",
    "pac_pipeline = Pipeline([('vect',TfidfVectorizer()),\n",
    "                         ('smote', SMOTE()),\n",
    "                 ('pac',PassiveAggressiveClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid_10 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'pac__max_iter': [50, 200, 500, 1000]}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_10 = GridSearchCV(estimator=pac_pipeline, \n",
    "                          param_grid=grid_10, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with TFIDF and MultinomialClassifier\n",
    "pac_pipeline2 = Pipeline([('vect',CountVectorizer()),\n",
    "                         ('smote', SMOTE()),\n",
    "                 ('pac',PassiveAggressiveClassifier())])\n",
    "\n",
    "# Define the grid\n",
    "grid_11 = [{'vect__stop_words': ['english'],\n",
    "         'vect__max_df': [0.7, 0.8],\n",
    "         'vect__min_df': [0, 0.5, 1.0],\n",
    "         'pac__max_iter': [50, 200, 500, 1000]}]\n",
    "\n",
    "# Define a grid search\n",
    "gs_11 = GridSearchCV(estimator=pac_pipeline2, \n",
    "                          param_grid=grid_11, \n",
    "                          scoring='f1_micro', \n",
    "                          cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aa39e",
   "metadata": {},
   "source": [
    "### 3.6.1 TFIDF Vectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs_10.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_10.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10389f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs_10.fit(x_im_stem_train, y_im_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_10.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81ccfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs_10.fit(x_im_lem_train, y_im_lem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_10.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec803b8",
   "metadata": {},
   "source": [
    "### 3.6.2 CountVectorizer Cross Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afba78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Original Text Dataset\n",
    "gs_9.fit(x_im_train, y_im_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_9.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2921a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using Lemmatized Text Dataset\n",
    "gs_9.fit(x_im_lem_train, y_im_lem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_9.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6304d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stemmed Text Dataset\n",
    "gs_9.fit(x_im_stem_train, y_im_stem_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best F1_Score: %.3f' % gs_9.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb1602",
   "metadata": {},
   "source": [
    "### 3.6.3 PassiveAggressiveClassifer Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674deff",
   "metadata": {},
   "source": [
    "Lemmatized TFIDF Vectorizor is the best model according to CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the model for tf-idf features\n",
    "pac_imb_pred = gs_10.predict(x_im_lem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef228b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the accuracy score for tfidf features\n",
    "pac_imb_score=accuracy_score(y_im_lem_test, pac_imb_pred)\n",
    "print(\"RandomForest TF-IDF accuracy score:\", pac_imb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set x_teset_tfidf value for Confusion Matrix Evaluation\n",
    "gs10_pac_tfidf = gs_10.best_estimator_.named_steps['vect'].transform(x_im_lem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_cm = plot_confusion_matrix(gs_10.best_estimator_.named_steps['pac'], gs10_pac_tfidf , y_im_lem_test)\n",
    "plt.suptitle(\"Imbalance Data PassiveAggressive Confusion Matrix\")\n",
    "plt.savefig('./images/Imb_Pac_CF.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14723b40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pac_roc = plot_roc_curve(gs_10.best_estimator_.named_steps['pac'] ,gs10_pac_tfidf, y_im_lem_test)\n",
    "plt.suptitle(\"Imbalance Data PassiveAggressive ROC Curve\")\n",
    "plt.savefig('./images/Imb_PAC_ROC.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c77130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pac_report = classification_report(y_im_lem_test, pac_imb_pred, target_names = ['0','1'])\n",
    "print(pac_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6a654",
   "metadata": {},
   "source": [
    "PassiveAgressive Model is doing great as well, but MultinomialClassifier model is slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0570a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc7c22",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c17a8",
   "metadata": {},
   "source": [
    "Although PassiveAggressive Model was a strong competitior, I concluded that MultinomialNB model being the optimal model for our dataset.<br>\n",
    "Compared to PassiveAggresive Model, MultinomialNB model was better in:\n",
    "1. Higher Accuracy & F1-Score\n",
    "2. Classified higher # of Fake News\n",
    "3. Classified higher # of Real News\n",
    "4. Lower False Negative \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da36e96",
   "metadata": {},
   "source": [
    "Sine MultinomialNB classifier is built to be suitable for classification with word counts for text classification, it is not a surprise that MultinomialNB was the optimal classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca748c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c3d10",
   "metadata": {},
   "source": [
    "## Ideas for Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34738fec",
   "metadata": {},
   "source": [
    "1. Try Unsupervised Learning Models. (Deep Learning)\n",
    "2. Try Web-Scraping from Fake News sites like Onions and see how well our model performs.\n",
    "3. Try Web-Scraping from Social Media and see the Fake News Detection Rate.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
